# T-Digest

--

### Idea Behind T-Digest

<span class="fragment">Group and interpolate:</span>

<ul>
<li class="fragment">number of groups between $N$ and $2N$ (compression factor)</li>
<li class="fragment">each group covers a range of quantiles</li>
<li class="fragment">number of data points per group determined by _scaling functions_</li>
<li class="fragment">each group $g$ is summarized by a centroid - a tuple of the form (sum, count)</li>
<li class="fragment">adding data points will either create or update groups/centroids</li>
</ul>

--

### Scaling Functions

<p class="fragment">
A *scaling function* $k$ is any strictly monotonically increasing function
taking input from real values in $[0, 1]$ and outputs one in $[0, 1]$
</p>
<p class="fragment">
Since function is strictly monotonically increasing, there is an
inverse.
</p>
<p class="fragment">
For t-digests, the scaling function is
$$
f(q, N) = \frac{sin^{-1}(2q - 1)}{\pi} + \frac{1}{2}
$$
</p>

--

### Width of the $i^{th}$ centroid


Given a list of centroids representing a distribution of numbers,
we want to compute the scaled size of the interval of quantiles covered
by a single centroid:

```
# centroid
class Centroid:
  def constructor(sum: float, weight: int):
    this.sum = sum
    this.weight = weight

  def value():
    return this.sum / this.weight
```

--

```python
@expect(0 < index < len(centroids))
def scaled_width(
  centroids: []Centroid,
  index: int,
  compression_factor: float
  inverse_scaling: float => float,
):
  left = centroids[0, index].map(lambda c: c.weight).sum()
  right = centroids[index].weight + left
  total = right + centroids[index + 1,].map(
    lambda c: c.weight).sum()

  return compression_factor * (inverse_scaling(right / total) - \
    inverse_scaling(left / total))
```

--

### T-Digest: Data Structure

<p class="fragment">
T-Digest with is an ordered sequence of centroids
$$
(s_1, c_1), (s_2, c_2),\dots,(s_n, c_n)
$$
</p>
<p class="fragment">
with two conditions:
</p>
<ul>
<li class="fragment">the width of a centroid has to be less than 1</li>
<li class="fragment">sum of widths of adjacent centroids must be greater than 1</li>
</ul>

--

### T-Digest and Centroid

```python
class TDigest:

  @expect(1 < len(centroids) < 2 * compress_factor < max_count)
  def constructor(
    compress_factor: int,
    scaling: float => float,
    centroids: []Centroid
    max_count: int
  ):

    this.compression_factor = compress_factor
    this.scaling = scaling
    this.centroids = centroids
```

--


### Adding a Data Point

Given a t-digest and a data point (`float`), update the t-digest
to include data:

<ol>
<li class="fragment">find the closest centroid(s)</li>
<li class="fragment">try merging the point to the centroids</li>
<li class="fragment">if any of them was width less than 1, then
  update the centroid with the biggest weight</li>
<li class="fragment">otherwise, add the point as a new centroid</li>
</ol>

--

### Nearest centroids

```python
class TDigest:
  # ...
  def find_nearest(data: float):
    min = FLOAT_MAX; min_index = 0
    for i, centroid in this.centroids:
      diff = abs(centroid.value() - data)
      if diff < min:
        min_index = i; min = diff

    next_diff = abs(
      this.centroids[min_index + 1].value() - data)
    if next_diff == min:
      return [min_index, min_index + 1]

    return [min_index]
```

--

### Adding a point to centroid

```python
class Centroid:
  # ...

  def add(data: float):
    return new Centroid(
      sum=centroid.sum + data,
      weight=centroid.weight + 1
    )
```

--

### Adding a data point to a T-Digest
```python
class TDigest:
  # ...
  def add_data_point(data: float):
    nearest_centroids = this.find_nearest_centroids(data)
    new_centroids = this.centroids.map(
      lambda i, centroid:
        i in nearest_centroids ? centroid.add(data) : centroid)
    lean_centroids = nearest_centroids.filter(lambda i:
      1 > scaled_width(new_centroids, i, ...))
    if empty(lean_centroids):
      this.centroids.add(new Centroid(data, 1))
    else:
      update = lean_centroids.sort(lambda i, j:
          this.centroids[i].weight < this.centroids[j].weight)[0]
      this.centroids[update] = this.centroids[update].add(data)
```

--

### Estimating Quantiles

Given a t-digest and a value $q$ between 0 and 1, find the quantile
at $q$:

<ol>
<li class="fragment">find the centroid that covers the quantile $q$</li>
<li class="fragment">use a linear distance to estimate difference
    between quantile and the centroid's value</li>
<li class="fragment">add the difference to the mean</li>
</ol>

--

### Find Centroid

Given a quantile $q$, find the index of centroid that covers the
quantile, and its left position:

```python
def find_centroid(
  centroids: []Centroid,
  quantile: float
):
  left = 0
  q_index = centroids.map(lambda c: c.weight).sum() * quantile
  for i, centroid in centroids:
    right = left + centroid.weight
    if right > q_index:
      return i, left

    left = right

  return len(centroids) - 1, left
```

--

### Linear Distance and difference

Given "location" of quantile (`q_index`), the left position of
centroid (`left`) and the number of elements in centroid (`weight`)
compute scaling factor:

```python
def t_distance(
  left: int,
  q_index: float,
  weight: int
):
  return (q_index - left) / weight - 0.5
```

--

### Interval Difference

Given a list of centroids and some index, compute the difference in
values between previous and next centroids (edge cases see below)


```python
@expect(0 < index < len(centroids))
def interval_difference(centroids: []Centroid, index int):
  switch index:
    case 0:
      return this.centroids[1].value() - this.centroids[0].value()

    case len(this.centroids) - 1:
      return this.centroids[index].value() - this.centroids[index - 1].value()

    default:
      return this.centroids[index + 1].value() - this.centroids[index - 1].value()
```

--

### Compute Quantile

```
class TDigest:
  @expect(0 <= q <= 1)
  def get_quantile(q: float) Maybe[float]:
    if empty(this.centroids):
      return None

    index, left = find_centroid(this.centroids, q)
    this_centroid = this.centroids[index]
    q_index = quantile * this.size()
    delta = interval_difference(this.centroids, index)
    scaling_factor = t_distance(
      left, q_index, this_centroid.weight)

    return this_centroid.value() + delta * scaling_factor
```

--

### Pseudo-Sketch: Combining Two T-Digests

<p class="fragment">
If we split a stream $A$ of data points into $A_1$ and $A_2$,
can we combine the t-digests of $A_1$ and $A_2$ to derive the
t-digest for $A$?
</p>
<ul>
  <li class="fragment">Q: can we combine two t-digests?</li>
  <li class="fragment">Q: combined vs the original?</li>
</ul>

--

### Combination Algorithm

Given two t-digests $T_1$ and $T_2$ with the same scaling function,
compute a t-digest that "summarises" both t-digests:

<ul>
<li class="fragment">merge the two lists of centroids</li>
<li class="fragment">starting with the first centroid, merge next
  centroids until the width would be greater 1</li>
<li class="fragment">repeat until all the centroids have been merged
  or visited</li>
</ul>

--

### Summing two centroids

```python
class Centroid:
  # ...
  def add(centroid: Centroid):
    return new Centroid(
      sum=this.sum + centroid.sum,
      weight=this.weight + centroid.weight)
```

--

### Grouping Indices

Given a list of weights and the inverse of a scaling function,
find grouping of indices such that the "width" in each group
does not exceed 1

--

```python
@expect(not empty(weights))
def group_weights(
  weights:    []int,
  scaling_fn: float => float,
  factor:     int
):
  inverse = scaling_fn.inverse()
  right, q_limit = weights[0], inverse(1)
  groups, current_group = [], [0]

  for i, weight in weights[1,]:
    new_right = right + weight
    if new_right / total > q_limit:
      groups.append(first_group)
      current_group = [i]
      q_limit = inverse(scaling_fn(right / total) + 1 / factor)

    else:
      current_group.append(i)
    right = new_right

  groups.append(current_group)
  return groups
```

--

### Combining two t-digests

```python
class TDigest:
  # ...
  def merge(other: TDigest):
    union = this.centroids.merge(other.centroids)
    weights = union.map(_.weight)
    groups = group_weights(
      weights, this.scaling.inverse(), this.compression_factor)

    new_centroids = groups.map(
      lambda group:
        group.map(lambda i: union[i])
             .sum(lambda x, y: x.add(y)))

    return new TDigest(new_centroids, ...)
```

--

### Why Quasi-sketch?

<ul>
<li class="fragment">the centroids don't always agree</li>
<li class="fragment">the errors of the combined t-digest
  has identical distribution</li>
<li class="fragment">conclusion: we can distribute quantile estimation
  across multiple workers</li>
</ul>

--

### Areas of Improvements

<ul>
<li class="fragment">each centroid may use standard deviation or
  higher order statistics</li>
<li class="fragment">computing with $\sin$ and $\sin^{-1}$ is expensive;
  there are other scaling functions of similar shape</li>
<li class="fragment">better interpolation formula</li>
<li class="fragment">conclusion: t-digest is the launching point for faster data
  structures with smaller memory footprint</li>
</ul>